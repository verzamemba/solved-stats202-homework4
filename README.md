Download Link: https://assignmentchef.com/product/solved-stats202-homework4
<br>
Homework problems are selected from the course textbook: <a href="http://www-bcf.usc.edu/~gareth/ISL/"><em>An Introduction to Statistical Learning</em></a><a href="http://www-bcf.usc.edu/~gareth/ISL/">.</a>

<strong>Problem 1 </strong>

Chapter 8, Exercise 4 (p. 332).

<strong>Problem 2 </strong>

Chapter 8, Exercise 8 (p. 333).

<strong>Problem 3 </strong>

Chapter 8, Exercise 10 (p. 334).

<strong>Problem 4 </strong>

Chapter 8, Exercise 11 (p. 335).

<h2>Problem 5</h2>

Let <em>x<sub>i </sub></em>: <em>i </em>= 1<em>,…,p </em>be the input predictor values andbe the K-dimensional output from a 2-layer and M-hidden unit neural network with sigmoid activation <em>σ</em>(<em>a</em>) = {1 + <em>e</em><sup>−<em>a</em></sup>}<sup>−1 </sup>such that

Show that there exists an equivalent network that computes exactly the same output values, but with hidden unit activation functions given by, i.e.

<em>Hint: first derive the relation between </em><em>σ</em>(<em>a</em>) <em>and </em><em>tanh</em>(<em>a</em>)<em>. Then show that the parameters of the two networks differ by linear transformations.</em>